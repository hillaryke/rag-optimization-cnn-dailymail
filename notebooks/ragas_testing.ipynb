{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the existing Chroma instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma(persist_directory=\"chroma\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='of news stories about a really sensitive issue that\\'s been very difficult for either party to solve.\"'),\n",
       " Document(page_content='and I\" (DW) This year, the jury chose two winners in the category Online: \"Digital journalism has a lot to offer. The two prizewinners represent a different approach in an interesting way and show how journalism generally evolves with multimedia possibilities,\" explains the jury. In the first contribution, Christian Salewski und Felix Rohrbeck track the disposal of electronic scrap in Germany and find out that it isn\\'t always legal and fair. In the second contribution, a group of Deutsche Welle trainees asked their grandmothers from Belarus, Brazil, Chile, China, Kenya and Germany about their'),\n",
       " Document(page_content='is, in journalism, if we gather the \"facts,\" we can usually find the answers to what we\\'re looking for.  When it comes to God, Jesus and the Holy Spirit, those answers rest in faith. As a journalist, I seek intellectual certainty. When it came to my faith, I felt intellectually embarrassed. There was so much I just couldn\\'t explain. When I started working on a documentary about the growth of atheism, I found myself in a profound place of reflection.  In the days when I thought I was going to pursue a life of ministry, I experienced and felt many things that were unexplainable.  What was that?')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What is the article about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize language model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "  llm = llm,\n",
    "  chain_type = \"stuff\",\n",
    "  retriever = retriever,\n",
    "  return_source_documents = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who bit Jon Huntsman in 2011\"\n",
    "# result = rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation the RAG system using RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contexts = [doc.page_content for doc in result[\"source_documents\"]]\n",
    "# formatted_context = pretty_print_docs(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ragas.ragas_pipeline import get_context_and_answer\n",
    "from src.ragas.ragas_utils import load_evaluation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = load_evaluation_data('data/evaluation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from typing import Dict, List\n",
    "def get_context_and_answer(\n",
    "    evaluation_data: List[Dict[str, List[str]]],\n",
    "    rag_chain, \n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"Retrieves context and generates answers for each question in the evaluation data.\n",
    "\n",
    "    Args:\n",
    "        evaluation_data (Dict[str, List[str]]): A dictionary containing:\n",
    "            - \"questions\": A list of questions.\n",
    "            - \"ground_truths\": A list of corresponding ground truth answers.\n",
    "        rag_chain: The RAG chain instance to use for retrieval and generation.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries, each containing:\n",
    "            - \"question\": The original question.\n",
    "            - \"context\": A string of concatenated relevant contexts.\n",
    "            - \"answer\": The generated answer from the RAG chain.\n",
    "            - \"ground_truth\": The ground truth answer (from the evaluation data).\n",
    "    \"\"\"\n",
    "\n",
    "    results = {\n",
    "        \"question\": [],\n",
    "        \"contexts\": [],\n",
    "        \"answer\": [],\n",
    "        \"ground_truth\": [],\n",
    "    }\n",
    "\n",
    "    for question, ground_truth in zip(\n",
    "        evaluation_data[\"questions\"], evaluation_data[\"ground_truths\"]\n",
    "    ):\n",
    "        response = rag_chain.invoke(question)\n",
    "        contexts_list = [doc.page_content for doc in response[\"source_documents\"]]\n",
    "                \n",
    "        results[\"question\"].append(question)\n",
    "        results[\"contexts\"].append(contexts_list)\n",
    "        results[\"answer\"].append(response[\"result\"])\n",
    "        results[\"ground_truth\"].append(ground_truth)\n",
    "        \n",
    "    dataset = Dataset.from_dict(results)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick one sample for testing from eval_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = eval_data['questions'][0]\n",
    "# ground_truth = eval_data['ground_truths'][0]\n",
    "\n",
    "# test_eval = {\"questions\": [question], \"ground_truths\": [ground_truth]}\n",
    "\n",
    "# test_data = get_context_and_answer(evaluation_data=test_eval, rag_chain=rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ac99cfa7834a15a4504abcfd562e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_correctness,\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "testset = get_context_and_answer(eval_data, rag_chain)\n",
    "\n",
    "# evaluating test set on listed metrics\n",
    "result = evaluate(\n",
    "    dataset=testset,\n",
    "    metrics=[\n",
    "        answer_correctness,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What upcoming animated project will feature Ad...</td>\n",
       "      <td>[(The Hollywood Reporter)The skies over Gotham...</td>\n",
       "      <td>The upcoming animated project that will featur...</td>\n",
       "      <td>Adam West and Burt Ward will be reprising thei...</td>\n",
       "      <td>0.806599</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What animated project did Adam West and Burt W...</td>\n",
       "      <td>[(The Hollywood Reporter)The skies over Gotham...</td>\n",
       "      <td>Adam West and Burt Ward announced an upcoming ...</td>\n",
       "      <td>Adam West and Burt Ward announced a new animat...</td>\n",
       "      <td>0.842686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What event is Rory McIlroy preparing for after...</td>\n",
       "      <td>[for 2014-15. He hurt his shoulder in December...</td>\n",
       "      <td>Rory McIlroy is preparing for Arnold Palmer's ...</td>\n",
       "      <td>Rory McIlroy is preparing for the U.S. Masters...</td>\n",
       "      <td>0.233269</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.863586</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Donald Trump help Rory McIlroy retriev...</td>\n",
       "      <td>[(CNN)With a little bit of help from Donald Tr...</td>\n",
       "      <td>Donald Trump, the owner of the Blue Monster co...</td>\n",
       "      <td>Donald Trump helped Rory McIlroy retrieve his ...</td>\n",
       "      <td>0.613383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893972</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What caused the collapse of the Iraqi army dur...</td>\n",
       "      <td>[of 2014. ISIS used speed, discipline and ruth...</td>\n",
       "      <td>The collapse of the Iraqi army during the ISIS...</td>\n",
       "      <td>The collapse of the Iraqi army during the ISIS...</td>\n",
       "      <td>0.770911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975391</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What upcoming animated project will feature Ad...   \n",
       "1  What animated project did Adam West and Burt W...   \n",
       "2  What event is Rory McIlroy preparing for after...   \n",
       "3  How did Donald Trump help Rory McIlroy retriev...   \n",
       "4  What caused the collapse of the Iraqi army dur...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [(The Hollywood Reporter)The skies over Gotham...   \n",
       "1  [(The Hollywood Reporter)The skies over Gotham...   \n",
       "2  [for 2014-15. He hurt his shoulder in December...   \n",
       "3  [(CNN)With a little bit of help from Donald Tr...   \n",
       "4  [of 2014. ISIS used speed, discipline and ruth...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The upcoming animated project that will featur...   \n",
       "1  Adam West and Burt Ward announced an upcoming ...   \n",
       "2  Rory McIlroy is preparing for Arnold Palmer's ...   \n",
       "3  Donald Trump, the owner of the Blue Monster co...   \n",
       "4  The collapse of the Iraqi army during the ISIS...   \n",
       "\n",
       "                                        ground_truth  answer_correctness  \\\n",
       "0  Adam West and Burt Ward will be reprising thei...            0.806599   \n",
       "1  Adam West and Burt Ward announced a new animat...            0.842686   \n",
       "2  Rory McIlroy is preparing for the U.S. Masters...            0.233269   \n",
       "3  Donald Trump helped Rory McIlroy retrieve his ...            0.613383   \n",
       "4  The collapse of the Iraqi army during the ISIS...            0.770911   \n",
       "\n",
       "   faithfulness  answer_relevancy  context_precision  \n",
       "0           1.0          0.000000           1.000000  \n",
       "1           1.0          0.000000           1.000000  \n",
       "2           0.5          0.863586           0.833333  \n",
       "3           1.0          0.893972           1.000000  \n",
       "4           1.0          0.975391           1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload testset to langsmith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a new dataset 'cnn_dailymail_testset'. Dataset is accessible at https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/920a9200-8c8c-46e5-a629-73bb91acaff9\n"
     ]
    }
   ],
   "source": [
    "from ragas.integrations.langsmith import upload_dataset\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/evaluation_set.csv\")\n",
    "\n",
    "# convert to dataset\n",
    "eval_set = Dataset.from_pandas(df)\n",
    "\n",
    "dataset_name = \"cnn_dailymail_testset\"\n",
    "dataset_desc = \"Synthetic testset data for Huggingface CNN Dailymail dataset.\"\n",
    "\n",
    "dataset = upload_dataset(eval_set, dataset_name, dataset_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-optimization-cnn-dailymail-hiPg4Kip-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
