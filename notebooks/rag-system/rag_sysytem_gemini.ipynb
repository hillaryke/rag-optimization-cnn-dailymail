{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag_pipeline import chunk_by_recursive_split, RAGSystem\n",
    "from src.env_loader import load_api_keys\n",
    "from src.ragas.ragas_pipeline import run_ragas_evaluation\n",
    "from src import display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_api_key = load_api_keys(\"OPENAI_API_KEY\")\n",
    "gemini_api_key = load_api_keys(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722428028.471122 2298355 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    }
   ],
   "source": [
    "llm_gemini = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
    "                 temperature=0.7, top_p=0.85)\n",
    "\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize embeddings and RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "# embeddings=HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "embeddings = gemini_embeddings\n",
    "\n",
    "# embeddings_model = 'text-embedding-ada-002'\n",
    "# embeddings_model = 'text-embedding-3-large'\n",
    "# embeddings = OpenAIEmbeddings(api_key=openai_api_key, model=embeddings_model)\n",
    "\n",
    "# embeddings=FastEmbedEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_system = RAGSystem(\n",
    "  # model_name = \"gpt-4o\",\n",
    "  existing_vectorstore = False,\n",
    "  embeddings = embeddings,\n",
    "  clear_store = True,\n",
    "  llm = llm_gemini,\n",
    "  # use_multiquery = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--SETUP NEW VECTORSTORE--\n",
      "--Split 1000 documents into 5030 chunks.--\n",
      "--USING BASE RETRIEVER--\n",
      "--SETUP RAG CHAIN--\n",
      "--RAGCHAIN SETUP COMPLETE!--\n"
     ]
    }
   ],
   "source": [
    "rag_system.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Who was Putin?\"\n",
    "result = rag_system.rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who was Putin?',\n",
       " 'answer': 'I do not have enough information to answer this question.',\n",
       " 'contexts': ['16, 2014, Crimea held a referendum on whether to continue as part of Ukraine or to cast its lot with the Russian Federation. The result was overwhelming, at least among those voting: 95% said they wanted to become part of Russia. A mere two days later, Russia annexed the territory. Putin said later that he had been planning the move even before the referendum was held. \"Friends!\" the President said in Red Square on Wednesday, according to his website, \"Exactly one year ago, Russia, which we are speaking of so much right now, and the Russian people showed amazing togetherness and patriotism in supporting the aspirations of the people of Crimea and Sevastopol to return to their native shores.\" The issue, he said, was \"our history, our spirituality and our statehood, the things that make us a single people and single united nation.\" Also participating, the website said, were \"popular Russian music groups and singers.\" Putin was recently out of sight without explanation for 10 days,',\n",
       "  \"to the Russian propaganda machine about the Ukrainian conflict. And he was instrumental in organizing the March 1 anti-war rally in Moscow -- a protest march he would have led, had he not been gunned down just hours before. The benefit of this murder to Putin wasn't just that it eliminated one opponent of the President, but that it will terrorize an entire class of dissidents. READ MORE: Other critics of Putin who ended up dead . Putin has a history of viciously attacking the most important person in any given group of enemies, in order to send a message to the rest of them. In 2003, he did this by arresting and imprisoning the richest oligarch in the country, Mikhail Khodorkovsky. When Khodorkovsky was put on trial in 2004, Putin allowed the television cameras film the wealthiest man in the country sitting in a cage. Imagine that you were the 17th richest man in Russia, and you saw a man more successful and influential than you sitting in a courtroom cage. What would you do? Anything\",\n",
       "  'there that are similar. You can go to a store and buy any kind of uniform.\" Question:  \"But were they Russian soldiers or not?\" Vladimir Putin:  \"Those were local self-defense units.\" Within weeks, Putin admitted they were Russian troops. At the same news conference, Putin said he saw no possibility of Crimea joining Russia and said Moscow would do nothing to \"provoke\" that. Two weeks later, he presided as the Russian parliament passed legislation annexing Crimea. In a documentary shown on Russian television last Sunday, Putin said he gave the order to take Crimea on February 23, 2014. So, it is clear that Putin can and does lie. But with that in mind, how should Western leaders who must deal with him actually do so? First of all, they should bear in mind Ronald Reagan\\'s \"trust but verify\" dictum. Second, while Putin may play fast and loose with the truth, he appears to be a rational actor who calculates costs and benefits. The challenge for the West is to structure agreements so that',\n",
       "  'his summer home in Crimea. He was visited by a group of high-ranking Soviet officials. The next day, the Russian people were told that Gorbachev was ill, and could not perform his duties. Gorbachev was held against his will. There was a coup in progress. Putin\\'s mentor, President Boris Yeltsin, also had a history of \"disappearing\" from view. He was really ill and/or drunk. Even if Putin is in perfect health and the social media whirlwind turns out to have just been an outlet for creativity, talk of Putin\\'s disappearance raises important questions. What would Russia become if he suddenly left power? Is there a successor in place? Is there anyone who would continue Putin\\'s policies? If there is a power vacuum, a conceivable scenario given just how thoroughly Putin dominates, what would the consequences be? Whatever Putin is doing at this exact moment -- whether he is hunting tigers, visiting with friends, or convalescing from an illness -- and no matter what he does in the days ahead,',\n",
       "  'in November 2006, he said he had no doubt about who was to blame for his imminent death. \"You may succeed in silencing me, but that silence comes at a price,\" Litvinenko said at the time. \"You may succeed in silencing one man, but the howl of protest from around the world will reverberate, Mr. Putin, in your ears for the rest of your life.\" Officials have always dismissed the accusation as \"nonsense,\" but suspicions linger. A Russian federal intelligence service spokesman went as far as to say that Moscow had not carried out any \"physical liquidation of unwelcome personalities\" since the Soviet era. The two prime suspects in the poisoning, Andrei Lugavoi and Dmitry Kovtun, are Russian nationals. Both are former agents of the Russian security services. But both deny involvement, and the Russian government refuses to extradite either to Britain to face trial. In January 2009, a masked man shot and killed Markelov, a Russian human rights lawyer known for his work on abuses by the Russian']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS Pipeline testing the rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragas Testing with Langsmith Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--LOADING EVALUATION DATA--\n",
      "--GETTING CONTEXT AND ANSWERS--\n",
      "--USING LANGSMITH FOR EVALUATION--\n",
      "Created a new dataset 'cnn_dailymail_evaluation'. Dataset is accessible at https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/8e291ee7-635e-40c2-ab54-1d2e8897e5f6\n",
      "View the evaluation results for project 'baseline_rag_benchmark' at:\n",
      "https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/8e291ee7-635e-40c2-ab54-1d2e8897e5f6/compare?selectedSessions=a58cdd46-9bf6-44ae-9ea4-f0853631205f\n",
      "\n",
      "View all tests for Dataset cnn_dailymail_evaluation at:\n",
      "https://smith.langchain.com/o/6691a6dd-a70e-56c0-8f45-a1f64338d797/datasets/8e291ee7-635e-40c2-ab54-1d2e8897e5f6\n",
      "[------------>                                     ] 5/19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run f591f3a5-4864-48c3-ac91-409ab305f428 with EvaluatorChain: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1558, in _request\n",
      "    response = await self._client.send(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpx/_client.py\", line 1661, in send\n",
      "    response = await self._send_handling_auth(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 142, in handle_async_request\n",
      "    await self._response_closed()\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 257, in _response_closed\n",
      "    await self.aclose()\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/httpcore/_backends/anyio.py\", line 55, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/anyio/streams/tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 1202, in aclose\n",
      "    self._transport.close()\n",
      "  File \"/usr/lib/python3.10/asyncio/selector_events.py\", line 706, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 753, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 515, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/langchain_core/tracers/evaluation.py\", line 127, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 210, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/langchain/chains/base.py\", line 166, in invoke\n",
      "    raise e\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/langchain/chains/base.py\", line 156, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/ragas/integrations/langchain.py\", line 80, in _call\n",
      "    score = self.metric.score(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/ragas/metrics/base.py\", line 105, in score\n",
      "    raise e\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/ragas/metrics/base.py\", line 101, in score\n",
      "    score = asyncio.run(self._ascore(row=row, callbacks=group_cm))\n",
      "  File \"/usr/lib/python3.10/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 649, in run_until_complete\n",
      "    return future.result()\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/ragas/metrics/_faithfulness.py\", line 263, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/ragas/llms/base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/ragas/llms/base.py\", line 170, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 724, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 684, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 883, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 741, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1295, in create\n",
      "    return await self._post(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n",
      "    return await self._request(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1582, in _request\n",
      "    return await self._retry_request(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1651, in _retry_request\n",
      "    return await self._request(\n",
      "  File \"/home/hilla/.cache/pypoetry/virtualenvs/rag-optimization-cnn-dailymail-hiPg4Kip-py3.10/lib/python3.10/site-packages/openai/_base_client.py\", line 1592, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: APIConnectionError('Connection error.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 19/19"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.answer_correctness</th>\n",
       "      <th>feedback.faithfulness</th>\n",
       "      <th>feedback.answer_relevancy</th>\n",
       "      <th>feedback.context_precision</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31f949c4-1476-4eb2-ae11-f23eb62af6d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.706439</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.887768</td>\n",
       "      <td>0.965509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.434766</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.203250</td>\n",
       "      <td>0.243470</td>\n",
       "      <td>0.225174</td>\n",
       "      <td>0.083576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693174</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.229624</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.334236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.579877</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.918437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.051280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.743723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.481985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.832633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.726066</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.482909</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.answer_correctness  feedback.faithfulness  \\\n",
       "count                     19.000000              18.000000   \n",
       "unique                          NaN                    NaN   \n",
       "top                             NaN                    NaN   \n",
       "freq                            NaN                    NaN   \n",
       "mean                       0.706439               0.851852   \n",
       "std                        0.203250               0.243470   \n",
       "min                        0.229624               0.250000   \n",
       "25%                        0.579877               0.687500   \n",
       "50%                        0.743723               1.000000   \n",
       "75%                        0.832633               1.000000   \n",
       "max                        1.000000               1.000000   \n",
       "\n",
       "        feedback.answer_relevancy  feedback.context_precision error  \\\n",
       "count                   18.000000                   18.000000     0   \n",
       "unique                        NaN                         NaN     0   \n",
       "top                           NaN                         NaN   NaN   \n",
       "freq                          NaN                         NaN   NaN   \n",
       "mean                     0.887768                    0.965509   NaN   \n",
       "std                      0.225174                    0.083576   NaN   \n",
       "min                      0.000000                    0.679167   NaN   \n",
       "25%                      0.918437                    1.000000   NaN   \n",
       "50%                      0.934425                    1.000000   NaN   \n",
       "75%                      0.963321                    1.000000   NaN   \n",
       "max                      1.000000                    1.000000   NaN   \n",
       "\n",
       "        execution_time                                run_id  \n",
       "count        19.000000                                    19  \n",
       "unique             NaN                                    19  \n",
       "top                NaN  31f949c4-1476-4eb2-ae11-f23eb62af6d3  \n",
       "freq               NaN                                     1  \n",
       "mean          2.434766                                   NaN  \n",
       "std           0.693174                                   NaN  \n",
       "min           1.334236                                   NaN  \n",
       "25%           2.051280                                   NaN  \n",
       "50%           2.481985                                   NaN  \n",
       "75%           2.726066                                   NaN  \n",
       "max           4.482909                                   NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--EVALUATION COMPLETE--\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TestResult' object has no attribute 'to_pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_rag_benchmark\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_dailymail_evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m rag_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ragas_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mrag_chain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrag_system\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrag_chain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m  \u001b[49m\u001b[43muse_langsmith\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m  \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m  \u001b[49m\u001b[43mupload_dataset_to_langsmith\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43msave_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/RizzBuzz/rag-optimization-cnn-dailymail/src/ragas/ragas_pipeline.py:86\u001b[0m, in \u001b[0;36mrun_ragas_evaluation\u001b[0;34m(rag_chain, use_langsmith, upload_dataset_to_langsmith, dataset_name, experiment_name, save_results, dataset_description)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TestResult' object has no attribute 'to_pandas'"
     ]
    }
   ],
   "source": [
    "# experiment_name = \"baseline_rag_benchmark_1\"\n",
    "# dataset_name = \"cnn_dailymail_evaluation\"\n",
    "\n",
    "# rag_results = run_ragas_evaluation(\n",
    "#   rag_chain=rag_system.rag_chain,\n",
    "#   use_langsmith=True,\n",
    "#   experiment_name=experiment_name,\n",
    "#   dataset_name=dataset_name,\n",
    "#   upload_dataset_to_langsmith=True,\n",
    "#   save_results=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Ragas tests locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--LOADING EVALUATION DATA--\n",
      "--EVALUATING LOCALLY--\n",
      "--GETTING CONTEXT AND ANSWERS--\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11674fb7d65844b28ace479d5a554184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--EVALUATION COMPLETE--\n",
      "--RESULTS SAVED--\n"
     ]
    }
   ],
   "source": [
    "rag_results = run_ragas_evaluation(\n",
    "  rag_chain=rag_system.rag_chain,\n",
    "  save_results=True,\n",
    "  experiment_name=\"embedding_model_bge_large\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-optimization-cnn-dailymail-hiPg4Kip-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
